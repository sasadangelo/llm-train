{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df787a3-ecc9-4192-9f88-815e826b5ca0",
   "metadata": {},
   "source": [
    "# LLM Trainer Demo\n",
    "\n",
    "In this demo, we will show how the training for large language models (LLM) works using the `transformers` library from Hugging Face. The training process can be divided in the following phases.\n",
    "* Run the computation on the MPS GPU on Mac;\n",
    "* Prepare the Tokenizer for the Input Dataset;\n",
    "\n",
    "We assume here that a training dataset is already available and it is a JSON lines files containing a bouch of questions and answers about the subject to instruct. This is the input [training set](train_merlinite_7b.jsonl).\n",
    "\n",
    "First of all, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e22cc1-c571-4ade-bada-8bcd8d1c0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f597c-bd8f-45b5-be0e-1d0dbcbec1b3",
   "metadata": {},
   "source": [
    "## Run the computation on the MPS GPU on Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db551c-5d47-43d4-bb54-fdc75127fb18",
   "metadata": {},
   "source": [
    "Check if MPS backend is available on the machine you're using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd2455b-837d-4291-8b34-c37ae014906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = \"mps\"\n",
    "torch_device = torch.device(device)\n",
    "print(f\"* Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859a9cb-3cce-4767-993b-653e781c3a84",
   "metadata": {},
   "source": [
    "## Prepare the Tokenizer for the Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08664dd5-e490-4e0e-ad5c-e4c0ab74ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
